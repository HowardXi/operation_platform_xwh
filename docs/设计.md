# 新的运维平台  

各种exporter -> prometheus -> influxdb  
定时脚本一部分到自定义的exporter, 
一部分直接写到memcache同时在exporter上留下时间戳  

运维后台从prometheus,influxdb,memcache获取数据   

数据和功能分层

## 1.物理机数据 views.host (不需要调整可适应新的业务环境或新的业务)
基础数据: lshw -> cron脚本 -> memcache
图: cpu/内存/硬盘/网络数据 从prometheus query_range获取
服务信息(系统服务数据和操作) 自定义agent脚本(dbus)


## 2.业务框架数据 views.business_service (跟业务紧密相关)
虚拟机数据/OVS数据/业务服务数据
采集 -> influxdb 通过host或者工程id查询分组
cron脚本 -> exporter


#### 2.1 虚拟机ovs等数据
memcache 和 influxdb
#### 2.2 java数据
等java给接口或者找找有没有某种exporter支持他们用的框架


## 3.服务数据(公共组件) (少调整)
消息队列 数据库 运维服务自身组件等
kafka-exporter/ mysql-exporter


## 4.运维功能 component (不需调整可适配各种业务)
webssh 文件分发 执行脚本等  
每部分单独成为组件通过supervisord管理


views.functions中只表示对组件的调用和数据传递 实际功能在components中的对应程序完成 (不需调整可适配各种业务)

所有数据返回的时候应该
```json
{
    "status": 0,
    "value": "",
    "timestamp": "",
    "msg":  ""
}
```
status可选字段 0成功 非0失败
msg可选字段失败原因
value如果是图的数据 []
timestamp 如果value表示一个数据可以用来检查数据多久没有更新了 
